= Red Hat Advanced Cluster Security for Kubernetes

[[outline]]

== Module outline

This module highlights the features of Red Hat Advanced Cluster Security for Kubernetes (RHACS) while monitoring and securing the patient-frontend application you deployed in the Quay module.

We will cover:

* Navigation basics
* Vulnerability management
* Policy management and enforcement

=== RHACS Basics
RHACS provides developers and administrators with tools to meet the security needs of cloud-native development on Kubernetes. Its features address primary security concerns across various environments, including datacenters, private clouds, and public clouds running Kubernetes clusters.

=== RHACS Features
With RHACS, you can achieve comprehensive security, covering key areas such as:

==== Vulnerability Management
Protect nodes, platforms, and applications from vulnerabilities using prioritization and impact-based filters.

==== Network Security
Gain real-time visibility, enforce network policies, detect anomalies, and manage app-centric network access controls.

==== Security Policy Guardrails
Ensure consistent, compliant, and secure configurations with RHACS' built-in policy guardrails.

==== Compliance
Make sure clusters meet regulatory and contractual requirements, such as DISA-STIG and PCI-DSS, with simple audit capabilities.

==== Risk Profiling
Identify and prioritize security risks using key impact and severity metrics for OpenShift and Kubernetes clusters.

==== Threat Detection and Response
Implement process and network controls to detect malicious runtime incidents and respond using Kubernetes-native enforcement.

[[console-access]]

=== Accessing the RHACS console

In this section, you will confirm that you can connect to the RHACS portal.

The following information will be available on the main lab screen:

- The RHACS Admin Credentials
- The URL for the RHACS portal

=== Logging into the RHACS console

Your RHACS Console is available at: {acs_route}[window=blank]

Administrator login is available with:

[cols="1,1"]
|===
| *RHACS Console Username:* | {acs_portal_username} |
| *RHACS Console Password:* | {acs_portal_password} |
|===

[[acs-nav]]

== Introduction to the RHACS console

The first section of this lab will focus on navigation and vulnerability management. This work will take place in the UI and require you to use both the dashboard and the lab environment.

=== Navigating the RHACS console

In this section, you familiarize yourself with the RHACS portal, including its tabs, search capabilities and dashboard functionality.

The RHACS dashboard has four main sections:

. Navigation bar
. Navigation drawer
. Dashboard

image::04-acs-numbered-dashboard.png[link=self, window=blank, width=100%, Numbered Dashboard]

=== Navigation bar

The top bar contains the following functionality: 

- Global search 
- Command-line tools 
- Cluster health 
- Documentation 
- API reference guide
- Enable dark/light Mode 
- Logged-in user account

=== 1. Global Search

The ability to instantly find resources is essential to safeguard your cluster. Utilize the RHACS search feature to find relevant resources faster.

For example, you can use it to find deployments exposed to a newly published CVE or all deployments with external network exposure.

A search query consists of two parts:

- An attribute that identifies the resource type you want to search for.
- A search term that finds the matching resource.

For example, to find all violations in the *frontend* deployment, the search query is *Deployment:frontend*.

In this search query, Deployment is the attribute, and frontend is the search term.

NOTE: The search field in RHACS requires each attribute to be entered fully as a search term. Enter your first attribute, and hit the <tab> key to move along to the following attribute you would like to enter. Results will appear once they match the entered query.

*Procedure*

. Click on the search bar 

image::04-acs-search.png[link=self, window=blank, width=100%]

[start=2]

. Enter "Deployment" + "patient-frontend" in the search bar

image::04-acs-search-patient-frontend.png[link=self, window=blank, width=100%]

NOTE: RHACS maintains a library of searchable assets to help you search faster, they will appear in a drop-down list, and you can click on them to enter them as well. If a specific CVE or deployment cannot be found, please confirm the spelling of the asset name or that it is correctly deployed in the cluster. 

==== Common search queries

Here are some common search queries you can try in the RHACS search bar if youâ€™d like to test its functionality.

|============
|Query|Example|Purpose
|CVE:<CVE_number>|CVE:CVE-2018-11776|Finding deployments that are affected by a specific CVE
|Privileged:<true_or_false>|Privileged:true|Finding privileged running deployments
|Exposure Level:<level>|Exposure Level:External|Finding deployments that have external network exposure
|============

image::04-acs-search-cve.png[link=self, window=blank, width=100%, Search Syntax]

NOTE: This is just a sample of the types of queries you can use to analyze your environment in RHACS. For additional examples of search queries, please see the RHACS documentation.

==== Local page filtering

You can use local page filtering from within all views in the RHACS portal. Local page filtering works similarly to the global search, but only relevant attributes are available. You can select the search bar to show all available attributes for a specific view.

=== 2. Navigation menu

image::04-acs-nav-01.png[link=self, window=blank, width=100%, Navigation Menu]

The left-hand navigation menu provides access to each of the security use cases, as well as product configuration to integrate RHACS with your existing tooling.

=== 3. Dashboard 

The Red Hat Advanced Cluster Security for Kubernetes (RHACS) Dashboard provides quick access to the data you need. It contains additional navigation shortcuts and actionable widgets that are easy to filter and customize so that you can focus on the data that matters most to you. You can view information about levels of risk in your environment, compliance status, policy violations, and common vulnerabilities and exposures (CVEs) in images.

image::04-acs-dashboard.png[link=self, window=blank, width=100%, Center Dashboard]

==== Navigating the main dashboard

The main dashboard is your place to look at the vulnerabilities, risk, compliance, and policy violations across your clusters and namespaces. This section addresses all of the functionality in the main dashboard to help you navigate it more effectively in the future.
The dashboard can be broken down into three main sections:

. The status bar
. The dashboard filter
. The actionable widgets

image::04-acs-dashboard-01.png[link=self, window=blank, width=100%, Three Dashboard Sections]

==== 1. The status bar

The status bar provides at-a-glance numerical counters for critical resources. The counters reflect what is visible with your current access scope, defined by the roles associated with your user profile. 

These counters are clickable, providing fast access to the desired list view pages as follows:

|============
|Counter|Destination
|Clusters|Platform Configuration -> Clusters
|Nodes|Configuration Management -> Applications & Infrastructure -> Nodes
|Violations|Violations Main Menu
|Deployments|Configuration Management -> Applications & Infrastructure -> Deployments
|Images|Vulnerability Management -> Dashboard -> Images
|Secrets|Configuration Management -> Applications & Infrastructure -> Secrets
|============

==== 2. The Dashboard filter 

The dashboard includes a top-level filter that applies simultaneously to all widgets. You can select clusters and one or more namespaces within selected clusters. Any change to the filter is immediately reflected by all widgets, limiting the data they present to the selected scope.

NOTE: The dashboard filter does not affect the status bar, and when no clusters or namespaces are selected, the view automatically switches to all.

image::04-acs-dashboard-02.png[link=self, window=blank, width=100%]

==== 3. Actionable widgets

If you have time, adjust the dashboard filtering options and widgets to hone the filtering capabilities.

With these widgets, you can customize the information displayed on the dashboard by default in order to find the items that you consider most important to your deployments and your business' security.

[[vuln-mgmt]]

=== RHACS Vulnerability Scanner

Red Hat Advanced Cluster Security for Kubernetes (RHACS) introduced Scanner V4 in version 4.4 as a Technology Preview to enhance container image vulnerability scanning. Built on ClairCore (the engine behind Clair v4), it offers better accuracy and broader support for programming languages and operating systems.

RHACS scans Go binaries, including dependencies from go.mod Supports Java (JAR/WAR/EAR), JavaScript (Node.js/npm), Python (egg and wheel), and Ruby (gem). RHACS adds support for Amazon Linux 2023, Alpine Linux 3.19, SUSE Linux Enterprise Server (SLES) 15, openSUSE Leap 15.1, Photon OS, and Oracle Linux.

For more information, take a look at the https://docs.openshift.com/acs/4.6/operating/examine-images-for-vulnerabilities.html[RHACS Scanner V4 documentation].


== The Vulnerability Management dashboard

Let us continue by looking at our primary use case for RHACS that is the Vulnerability Management features and dashboard, a familiar topic for most security teams.

NOTE: For the following section, please note that the order in which the images appear or the number of components affected may vary depending on versions and other applications running in the cluster.

=== Vulnerability Management - Workload CVE

The Vulnerability Management tab in RHACS has seen significant improvements over the past year. It now focuses on categorizing vulnerabilities by workload, enabling scans for RHEL CoreOS, node-level issues, and correlating them with platform and application vulnerabilities. This helps security teams identify the software layer where the issue exists and the right team to address it.

More critical than fixing individual vulnerabilities is establishing a process to keep container images updated and prevent serious, fixable vulnerabilities from advancing through the pipeline. 

image::04-workload-1.png[link=self, window=blank, width=100%]

The *Workload CVE dashboard* shows hundreds of vulnerabilities, over 200 images, and 300+ deployments because multiple images are used across different deployments.

NOTE: The numbers may be different in your environments. 

Now it's time to find the same *patient-frontend* application and do some dissecting.

.Procedure

. Click the *Vulnerability Management -> Workload CVEs* tab
. Click the dropdown and select deployment.

image::04-workload-2.png[link=self, window=blank, width=100%]

[start=2]
. Click the second dropdown and select name.

image::04-workload-3.png[link=self, window=blank, width=100%]

[start=2]
. Then, filter for the *frontend* deployment.

image::04-workload-4.png[link=self, window=blank, width=100%]

You will notice that an extra filter was added to the default filters, showing only the single deployment that the "Developer" built in the Quay module.

[start=3]
. Click the *CVE* tab

image::04-workload-5.png[link=self, window=blank, width=100%]

From here you can analyze the vulnerabilites that the devoplers have introduced into the environment. 

====
CVE-2017-18342 & CVE-2020-14343 both are critical and are specific to the PyYAML package. This package is a high impact fix for the developers to focus on. 
====

image::04-workload-6.png[link=self, window=blank, width=100%]

IMPORTANT: Container OS age and the age of its components are a massive correlating factor to the number of vulnerabilites present. Speed is security when it comes to containers. 

[start=4]
. Click the *CVE-2020-14343* blue link.

image::04-workload-7.png[link=self, window=blank, width=100%]

If you're focused on a specific vulnerability, it's very helpful to see all the components it affects. With this dashboard you can see that our response to this vulnerability needs to be targeted, you should reach out directly to the development team that needs that PyYAML package.


IMPORTANT: As a security team our next step is to inform the development team about these vulnerabilities. Luckily, they should have already seen these issues in Quay. 

=== Vulnerability reporting

Internal vulnerability reporting improves software security by helping teams fix issues early, lowering the risk of breaches and failures. It promotes a security-focused mindset and ensures critical vulnerabilities are prioritized and resolved quickly, resulting in a more reliable product and increased user trust.

In the next part of the module, you will create a vulnerability report for the frontend application that would be sent to the developer team.

.Procedure

. Let's start by clicking on the *Vulnerability Reporting* tab. 

image::04-vr-1.png[link=self, window=blank, width=100%]

[start=2]
. Click the *Create report* button.

image::04-vr-2.png[link=self, window=blank, width=100%]

You will see that creating a report is a three step process. It requires you to configure the report parameters and the delivery destination, and then you have to review and create your report.

The configurable parameters are the following:

- Report name
- Report description
- CVE severity
- CVE status
- Image type
- CVEs discovered since (with a date)
- And a Report scope.

[start=3]
. Fill out the information specific to the frontend deployment of the patient-portal.

- Report name: frontend-vulnerability-report
- Report description (Optional)
- CVE severity: Critical + Important
- CVE status: Fixable + Unfixable
- Image type: Deployed + Watched
- CVEs discovered since: All time (It's been a short lab :) )
- Include NVD CVSS

image::04-vr-3.png[link=self, window=blank, width=100%]

====
You now have a vulnerability report but you haven't targeted it to the frontend deployment. That's what collections are for.
====

[start=4]
. Click on the "Select a collection" dropdown then select *Create collection*.

image::04-vr-4.png[link=self, window=blank, width=100%]

[start=5]
. When you are done, select the *Select a collection* dropdown
. Click *Create Collection*

image::04-vr-4.png[link=self, window=blank, width=100%]

You can create collection rules by deployment, namespace and cluster. The collections are setup this way so that you can easily attach policies, vulnerability reports and notifications by the logical groupings of your organization. 

Since you want to target only a single deployment, let's add the Deployment and Namespace specific to the frontend deployment.

[start=6]
. Give the collection a name. (ex: frontend)
. Click the dropdown and select *Deployments with names matching* then enter *frontend*

image::04-vr-5.png[link=self, window=blank, width=100%]

[start=8]
. Do the same with the namespace rule. Select *Namespace with names matching* then enter *patient-portal*

====
If you do this correctly the frontend deployment you are targeting should never disappear from the "collection results" information on the right of the screen.
====

image::04-vr-6.png[link=self, window=blank, width=100%]

[start=9]
. Review the collection
. Scroll down and hit *Save*
. Click *Next* once you are back in the *Configure report parameters* tab


Next, create an example email notifier that will send an email every Monday to remind the frontend team about the vulnerabilities in the deployment.

====
This notifier will not work but will show you what is possible with RHACS.
====

[start=12]
. Click *Add delivery destination -> Create email notifier* and enter the following

Integration name: frontend-example
Email server: smtp.example.com:465
Click *Enable unauthenticated SMTP*
From: security team
Sender: rhacs@demo.com
Default recipient: frontend@fix-this.com

image::04-vr-8.png[link=self, window=blank, width=100%]

NOTE: Don't worry if you don't want to enable the notification. The exercise is about going through the workflow. 

[start=12]
. Select a frequency. For example, weekly on Monday.
. Hit *Next*
. Review your masterpiece and click *Create*

image::https://media1.giphy.com/media/v1.Y2lkPTc5MGI3NjExOWJ0ZWRjZ3g0OTUyOGE5MDVhdDgyZzVhczcwNGdpbWxibzBhejZzMyZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/VdiQKDAguhDSi37gn1/giphy.gif[itsalive]

However, you don't have to wait until Monday to view the report.

[start=15]
. Click the vertical ellipses on the right side of the UI and click *Generate Download*

image::04-vr-9.png[link=self, window=blank, width=100%]

[start=16]
. Download the report and take a look if you have the time.

Awesome!

Now that the development team is getting weekly reports about their vulnerabilities it's time to create some guardrails for the applications behavior. 

== Policy Management

RHACS includes built-in policies to detect attacker activities like gaining access, maintaining presence, lateral movement, and data exfiltration. Its continuous runtime monitoring observes container activity and enforces appropriate responses. RHACS goes further by leveraging containers' ephemeral and immutable nature to improve security proactively.

We use runtime incidents and vulnerabilities as opportunities to enhance security by defining policies and enforcing them early in the CI/CD process.

In the next section, you'll focus on identifying and enforcing a runtime policy. For this example, you'll stop the alpine package manager from running in our frontend application. Specifically, you'll ensure the frontend container never triggers updates while in our clusters.

[[runtime-enforce]]

== Runtime policy enforcement

RHACS monitors container processes and collects data to help you create policies that block unwanted behaviors. This data can also be used to build baseline policy configurations for further refinement.

Package managers like apt (Ubuntu), apk (Alpine), or yum/dnf (Red Hat) are tools for managing software on Linux systems. While essential for managing virtual machines, using them in running containers violates the immutable nature of container operations.

This policy shows how RHACS detects and prevents runtime violations by using Linux kernel instrumentation to identify running processes and OpenShiftÂ® to terminate pods as enforcement. OpenShift enforcement is preferable to rules applied directly to containers or container engines, as it ensures consistency with OpenShift's maintained state.

By terminating the container upon detecting runtime policy violations, you not only enforce the immutable principle but also stop an attack before it progresses further.

*Procedure*

. On the left-hand side of the application, click the *Platform Configuration* tab and select *Policy Management*.

image::04-acs-policy-00.png[link=self, window=blank, width=100%, Policy Management Dashboard]

[start=2]

. Filter through the policies to find *Alpine Linux Package Manager Execution* or use the search bar to select *Policy* then *Alpine Linux Package Manager Execution*.

image::04-acs-policy-01.png[link=self, window=blank, width=100%, Policy Management Search]

[start=3]

. Once you have found the policy *Alpine Linux Package Manager Execution* click on the three dots then click *Clone policy*.

image::04-acs-policy-02.png[link=self, window=blank, width=100%]

NOTE: This is a system policy. If you change a system policy they get reset upon the next release. It is always best practice to clone such policies. 

[start=4]

. Give the policy a new name: *Alpine Linux Package Manager Execution - Enforce*

image::04-acs-policy-03.png[link=self, window=blank, width=100%]

[start=5]

. Click *Next*

image::04-acs-policy-04.png[link=self, window=blank, width=100%]

[start=6]

. The lifecycle stages don't need to be changed so click *Next*
. The *rules* don't need to be changed either since you are already targeting the *apk* process. Click *Next*

image::04-acs-policy-05.png[link=self, window=blank, width=100%]

====
The Policy behavior section allows you to exclude specific deployments from this policy. Some RHACS users have golden applications that they always want excluded from enforcement policies. This would be where you add those exceptions. 
====

[start=8]
. Click *Next*
. In the *Policy behavior -> Actions* tab select *inform and enforce* 
. Enable runtime enforcement by clicking the *inform and enforce* button.
. Configure enforcement behavior by selecting *Enforce at Runtime*.
. Click *Next*

image::04-acs-policy-06.png[link=self, window=blank, width=100%, Enforce Runtime Policy]

[start=13]

. Review the policy changes
. Click *Save*

IMPORTANT: Make sure to save the policy changes! If you do not save the policy, the process will not be blocked!

=== Testing the runtime policy

Next, you will use tmux to watch OpenShift events while running the test so you can see how RHACS enforces the policy at runtime.

*Procedure*
[start=1]

. start tmux with two panes:

[source,sh,role=execute]
----
tmux new-session \; split-window -v \; attach
----

[start=2]

. Next, run a watch on OpenShift events in the first shell pane:

[source,sh,role=execute]
----
oc get events -n patient-portal -w
----

[start=3]

. Press *Ctrlb, o* to switch to the next pane. (Ctrlb THEN o)
. Exec into our *patient-frontend* application by getting the pod details and adding them to the following command.

[source,sh,role=execute]
----
POD=$(oc get pod -n patient-portal -l app=frontend -o jsonpath="{.items[0].metadata.name}")
oc exec -n patient-portal $POD -i --tty -- /bin/sh
----

*Sample output*
[source,bash]
----
[demo-user@bastion ~]$ POD=$(oc get pod -n patient-portal -l app=frontend -o jsonpath="{.items[0].metadata.name}") 
oc exec -n patient-portal $POD -i --tty -- /bin/sh
/home/fritz $ 
----

NOTE: If you see */home/fritz $* you've confirmed you have a shell and access to the frontend application.

[start=5]
. Run the alpine package manager in this shell:

[source,sh,role=execute]
----
apk update
----

. Examine the output and expect to see that the package manager attempts to perform an update operation:

[source,texinfo,subs="attributes"]
----
/home/fritz $ apk update
ERROR: Unable to lock database: Permission denied
ERROR: Failed to open apk database: Permission denied
/home/fritz $ command terminated with exit code 137
[demo-user@bastion ~]$ 
----

[start=6]
. Examine the oc get events tmux pane (The pane on the bottom), and note that it shows that RHACS detected the package manager invocation and deleted the pod:

[source,texinfo,subs="attributes"]
----
^C^C[demo-user@bastion ~]$ oc get events -n patient-portal -w
LAST SEEN   TYPE      REASON                 OBJECT                           MESSAGE
50s         Normal    Killing                pod/frontend-8667d5c56b-f9fcj    Stopping container frontend
50s         Normal    Scheduled              pod/frontend-8667d5c56b-s6dph    Successfully assigned patient-portal/frontend-8667d5c56b-s6dph to ip-10-0-61-109.us-east-2.compute.internal
49s         Normal    AddedInterface         pod/frontend-8667d5c56b-s6dph    Add eth0 [10.131.0.167/23] from ovn-kubernetes
49s         Normal    Pulling                pod/frontend-8667d5c56b-s6dph    Pulling image "quay-czscm.apps.cluster-czscm.czscm.sandbox478.opentlc.com/quayadmin/frontend:0.1"
49s         Normal    Pulled                 pod/frontend-8667d5c56b-s6dph    Successfully pulled image "quay-czscm.apps.cluster-czscm.czscm.sandbox478.opentlc.com/quayadmin/frontend:0.1" in 46ms (46ms including waiting). Image size: 117738460 bytes.
49s         Normal    Created                pod/frontend-8667d5c56b-s6dph    Created container frontend
49s         Normal    Started                pod/frontend-8667d5c56b-s6dph    Started container frontend
50s         Normal    SuccessfulCreate       replicaset/frontend-8667d5c56b   Created pod: frontend-8667d5c56b-s6dph
50s         Warning   StackRox enforcement   deployment/frontend              A pod (frontend-8667d5c56b-f9fcj) violated StackRox policy "Alpine Linux Package Manager Execution - Enforce" and was killed
----

NOTE: After a few seconds, you can see the pod is deleted and recreated. In your tmux shell pane, note that your shell session has terminated and that you are returned to the Bastion VM command line.

[start=7]

. Type exit in the terminal, use ctrl+c to stop the 'watch' command, and type exit one more time to get back to the default terminal.

Congrats! You have successfully stopped yourself from downloading malicious packages! However, the security investigative process continues, as you have now raised a flag that must be triaged! you will triage our violations after you look at deploy time policies.

[[deploy-enforce]]

== Introduction to *Deploy-Time & Build-time* policy enforcement

=== Deploy-Time policy enforcement

Deploy-time policies enforce configuration controls within the cluster and during the CI/CD process to prevent misconfigurations before deployment. In this example, we'll ensure the Ubuntu Package Manager never makes it into the default namespace.

RHACS provides two ways to enforce deploy-time policies:

1. With Admission Controller Enabled (Listen and Enforce Mode). RHACS rejects deployments that violate policy before they are created.
Without Admission Controller Enabled:

2. RHACS scales the pod replicas to zero, effectively preventing the deployment from running. 

In the next example, weâ€™ll configure a Deploy-Time policy to block the frontend application from deploying into the patient-portal namespace if the image contains the alpine package manager.

=== Build-Time policy enforcement

Build-time policies in RHACS help prevent misconfigurations or vulnerabilities from being introduced during the build process, before deployment even occurs. These policies are focused on ensuring that the code and images being built meet security and configuration standards.

RHACS provides two ways to enforce build-time policies:

With Build Scanning Enabled (Enforce Mode): RHACS scans the container image for vulnerabilities or policy violations during the build process. If any issues are detected, the build is rejected, preventing the image from being pushed to the registry.

Without Build Scanning Enabled: RHACS allows the image to be built, but after scanning, it marks the image as non-compliant and provides a warning. The image can still be pushed to the registry, but itâ€™s flagged for review before deployment.

== Prevent the Alpine Package Manager in the frontend image from being deployed

*Procedure*

. Navigate to *Platform Configuration â†’ Policy Management*.

. On the *Policy Management* page, type *Policy* then *alpine* into the filter bar at the top.

NOTE: This time you are going to edit a different policy. Specifically related to the *Build & Deploy* phases.

image::04-acs-deploy.png[link=self, window=blank, width=100%]

[start=3]

. Click on the *Alpine Linux Package Manager (apk) in Image* options (The three dots on the right side of the screen) and select *Clone policy*

IMPORTANT: Make sure to *CLONE* the policy

image::04-acs-deploy-1.png[link=self, window=blank, width=100%]

[start=4]

. Give the policy a new name. For example: *Alpine Linux Package Manager (apk) in Image - Build and Deploy - Enforce*

IMPORTANT: Since this is a "Build and Deploy" lifecycle policy, when you begin enforcing the policy it will be enforce in BOTH lifecycle phases. You will enable enforcement in both to save time since the next section will review the build phase of 

[start=5]

Now, you want to target the frontend deployment by it's namespace

. Click on the *Policy behavior -> Scope* tab.
. Click on *Add inclusion scope*.
. Select *Cluster=Production* & *Namespace=patient-portal* & *app=frontend*

image::04-acs-deploy-2.png[link=self, window=blank, width=100%]

[start=8]

. Next, head to *Policy behavior -> Actions*.
. Update the policy to *inform and enforce*

image::04-acs-deploy-3.png[link=self, window=blank, width=100%]

[start=10]

. Lastly, go to the *Review Policy* tab

Your policy should look like this,

image::04-acs-deploy-4.png[link=self, window=blank, width=100%]

NOTE: There is a preview tab on the right side of the page that will show you all of the affected applications with the introduction of this policy. Because you targeted the frontend app specifically you will only see that container. 

[start=11]
. Click Save

image::04-acs-deploy-5.png[link=self, window=blank, width=100%]


Congrats! You're now enforcing at runtime and deploy time. In the last step in this module. you will review

=== Enforcement

Let's go through what the developer will now see when building and redeploying the frontend application.

Procedure

. Tag and push the updated image to the Quay registry.

[source,sh,subs="attributes",role=execute]
----
podman tag $QUAY_URL/$QUAY_USER/frontend:0.1 $QUAY_URL/$QUAY_USER/frontend:0.2
podman push $QUAY_URL/$QUAY_USER/frontend:0.2
----

[start=2]
. Perform an image security scan using roxctl to check for policy violations.

[source,sh,subs="attributes",role=execute]
----
roxctl -e $ROX_CENTRAL_ADDRESS:443 image check --image $QUAY_URL/$QUAY_USER/frontend:0.2
----

[start=3]
. Review the output of the scan to identify any security policy violations.

[.console-output]
[source,bash,subs="+macros,+attributes"]
----
+--------------------------------+----------+--------------+--------------------------------+--------------------------------+--------------------------------+
|  Alpine Linux Package Manager  |   LOW    |      -       | Alert on deployments with the  |   - Image includes component   |      Run apk --purge del      |
|         (apk) in Image         |          |              |  Alpine Linux package manager  |      'apk-tools' (version      | apk-tools in the image build  |
|                                |          |              |         (apk) present          |           2.14.6-r2)           |   for production containers.   |
+--------------------------------+----------+--------------+--------------------------------+--------------------------------+--------------------------------+
WARN:   A total of 3 policies have been violated
ERROR:  failed policies found: 2 policies violated that are failing the check
ERROR:  Policy "Fixable Severity at least Important" - Possible remediation: "Use your package manager to update to a fixed version in future builds or speak with your security team to mitigate the vulnerabilities."
ERROR:  Policy "Alpine Linux Package Manager (apk) in Image - Enforce Build and Deploy" - Possible remediation: "Run apk --purge del apk-tools in the image build for production containers."
ERROR:  checking image failed: failed policies found: 2 policies violated that are failing the check
----

[start=4]
. Update the frontend deployment manifest with the new image and apply the changes.

[source,sh,subs="attributes",role=execute]
----
sed -i "s|image: .*|image: ${QUAY_URL}/${QUAY_USER}/frontend:0.2|" $TUTORIAL_HOME/skupper-demo/frontend.yml
oc apply -f $TUTORIAL_HOME/skupper-demo/frontend.yml
----

[start=5]
. Observe the deployment error due to policy enforcement.

[.console-output]
[source,bash,subs="+macros,+attributes"]
----
Resource: "apps/v1, Resource=deployments", GroupVersionKind: "apps/v1, Kind=Deployment"
Name: "frontend", Namespace: "patient-portal"
for: "/home/demo-user/demo-apps/skupper-demo/frontend.yml": error when patching "/home/demo-user/demo-apps/skupper-demo/frontend.yml": admission webhook "policyeval.stackrox.io" denied the request:
The attempted operation violated 1 enforced policy, described below:

Policy: Alpine Linux Package Manager (apk) in Image - Enforce Build and Deploy

Description:
âž› Alert on deployments with the Alpine Linux package manager (apk) present

Rationale:
âž› Package managers make it easier for attackers to use compromised containers,
since they can easily add software.

Remediation:
âž› Run apk --purge del apk-tools in the image build for production containers.

Violations:

Container 'frontend' includes component 'apk-tools' (version 2.14.6-r2)

In case of emergency, add the annotation {"admission.stackrox.io/break-glass": "ticket-1234"} to your deployment with an updated ticket number
----

== Report and Resolve Violations

In this section, you will resolve a few of the issues that you have created.

*Procedure*

. Navigate to the Violations page.
. Filter by the policy violation Policy - Name - r/apk OR by the most recent policy violations. You will see a policy violation that has been enforced.
. Click the most recent violation and explore the list of the violation events.

image::04-acs-violations.png[link=self, window=blank, width=100%, Violations Menu]

If configured, each violation record is pushed to a Security Information and Event Management (SIEM) integration and is available to be retrieved via the API. The forensic data shown in the UI is recorded, including the timestamp, process user IDs, process arguments, process ancestors, and enforcement action.

IMPORTANT: You must resolve the issue before it can be marked as resolved.

[start=4]
. Remove the deployment that violates the policy.

[source,sh,subs="attributes",role=execute]
----
oc delete -f $TUTORIAL_HOME/skupper-demo/frontend.yml
----

[start=5]
. After addressing the issue, mark the violation as resolved.

image::04-acs-resolve.png[link=self, window=blank, width=100%]

== Implement Policy-as-Code in ACM with OpenShift GitOps

Your last task is to externally manage ACS policies through OpenShift GitOps. To make this easier, the policies from before have already been exported to a GitHub repository.

link:https://github.com/mfosterrox/skupper-security-demo/tree/main/PaC-custom-policies[PaC Custom Policies on GitHub]

*Procedure*

. Navigate to OpenShift GitOps: Go to the OpenShift Console and search for "OpenShift GitOps"
. Create a new GitOps Application: In the GitOps dashboard, click on "New Application" to create a new application.
. Configure the Application:
Name: Give the application a name, e.g., pac-custom-policies.
. Select the Argo server, "openshift-gitops"
. Hit "Next"
. Enter the URL of the GitHub repository containing the custom policies (https://github.com/mfosterrox/skupper-security-demo.git).
. Select "Main"
. Select "PaC-custom-policies"
. Enter the remote namespace of "stackrox"
. Make sure the "Replace resources instead of applying changes from the source repository" is selected.
. *Deploy application resources on clusters with all specified labels*
* Cluster sets: *default*
* Label: *local-cluster*
* Operator: *equals any of*
* Value: *true*

== Conclusion

In this lab, you used Red Hat Advanced Cluster Security for Kubernetes (RHACS) to identify potential security violations in your cluster through a central dashboard. You created both deploy-time and runtime policies to help prevent malicious activities from occurring.

This lab aimed to demonstrate the significant value RHACS and OpenShift Platform Plus provide in enhancing cluster security. Feel free to continue exploring the RHACS lab environment to deepen your understanding.
